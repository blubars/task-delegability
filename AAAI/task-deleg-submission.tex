\def\year{2018}\relax
%File: formatting-instruction.tex
\documentclass[letterpaper]{article} %DO NOT CHANGE THIS
\usepackage{aaai18}  %Required
\usepackage{times}  %Required
\usepackage{helvet}  %Required
\usepackage{courier}  %Required
\usepackage{url}  %Required
\usepackage{graphicx}  %Required
\frenchspacing  %Required
\setlength{\pdfpagewidth}{8.5in}  %Required
\setlength{\pdfpageheight}{11in}  %Required
%PDF Info Is Required:
  \pdfinfo{
/Title (Not Can We, But Should We: A Design Framework on Appropriate Levels of Automation)
/Author (Chenhao Tan, Brian Lubars)}
\setcounter{secnumdepth}{0}  
 \begin{document}
% The file aaai.sty is the style file for AAAI Press 
% proceedings, working notes, and technical reports.
%
\title{Not Can We, But Should We: \\A Design Framework on Appropriate Levels of Automation}

\author{Chenhao Tan \and Brian Lubars\\
Department of Computer Science\\
University of Colorado, Boulder\\
{chenhao.tan, brian.lubars}@colorado.edu\\
}

%\newcommand{\citet}[1]
%{\citeauthor{#1} ̃\shortcite{#1}}
%\newcommand{\citep}{\cite}
%\newcommand{\citealp}[1]
%{\citeauthor{#1} ̃\citeyear{#1}}

\maketitle
\begin{abstract}
Humans and machines offer complementary abilities. Some tasks are suitable for automation (machine control), some should arguably not be automated (human control), and some are amenable to a mix of the two (human-in-the-loop or machine-in-the-loop designs). What factors go into this classification? When is one paradigm more appropriate than another? By examining factors behind task delegation, human ability, and machine ability for a variety of tasks, we aim to develop a taxonomy of task spaces which help contextualize research and design choices for designing more human-centered automated systems.
\end{abstract}

\section{AI Agents}
Autonomous computer systems that accomplish tasks in dynamic and uncertain environments are increasingly considered with an agent-based design. Key characteristics of an agent-based design include that the system is an entity designed for a specific purpose (achieve a goal), is autonomous, and capable of problem-solving in response to the environment \cite{jennings-2000}. Advantages of such a design are a more unified and powerful interface that abstracts away unnecessary details, and the potential for intelligent cooperation and connection between different systems \cite{bradshaw}

Note: Perhaps we're less concerned with an "agent" design, and more concerned with general autonomous systems? 

\section{Task Delegation}

\cite{milewski1} proposes a "delegation stance", a term encompassing the complex factor interactions that result in possible delegation to either a human or computer. They find this useful in combining information across disciplines, since much delegation research is between humans. Broadly, delegation factors can be broken down into three categories: delegator characteristics, delegator perception of delegate characteristics, and situational variables.

Prior research indicates that people are willing to delegate in the following scenarios \cite{milewski1}: 
\begin{enumerate}
    \item When the agent is perceived as competent
    \item When the agent is perceived as trustworthy and confident
    \item When the agent is perceived as similar to the delegator
    \item When the delegator is experienced or confident in the situation
    \item When the workload or nature of work necessitates it
    \item When delegation benefits the participants: maximize overall performance and incentive structures, motivation or morale or skill-building in delegate, or building a relationship between the the delegator and the delegate (if human).
\end{enumerate}

Though we are focused on whether a subject is willing to delegate or not, it is worth noting that we are ignoring many situational variables relating to practical delegation. These include the frequency of delegation, the amount of monitoring done by the person delegating \cite{milewski1}, and the workload of delegator \cite{leana1986predictors}.

\section{Task and Human Factors of Delegation}
To explain the human and task factors behind a task delegation decision, we consider a model with four main dimensions: a person's \textbf{motivation} in undertaking the task, their perception of the task's \textbf{difficulty}, their perception of \textbf{risk} associated with accomplishing the task, and finally their \textbf{trust} in the AI agent to accomplish the task.

We propose that an AI delegation decision depends on factors related to task traits, task-specific personality traits, and general personality traits.

\subsection{Purpose}
The purpose dimension examines the reasons someone may be interested in accomplishing a given task and to the expected utility that accompanies the task's successful completion. How important is accomplishing this task, and why? Is the task personally meaningful? Is it a stepping-stone to a larger goal, or an end in itself? We further decompose purpose into three sub-factors: the \textbf{intrinsic motivation} or interest, \textbf{goal}, and the \textbf{utility}/importance of the task.

According to Locke, motivation and cognition are collectively responsible for determining action. Motivation is an energizing function that helps initiate and sustain task-related actions, and arises through interactions between a person and the environment \cite{latham2005work}. Motivation can affect action by directing our attention towards achieving values or goals, and by regulating the intensity and persistence of actions. Cognition matters because we can choose which values or goals to act on and adjust our values through thought \cite{Locke-motivation-2000}. Since motivation drives action, people are unlikely to choose self-delegate a task for which they have no motivation if given a choice. This suggests \textbf{intrinsic motivation} to be a likely factor in task delegation.

\cite{thomas-intrinsic-motiv} suggests four cognitions which are responsible for additively producing intrinsic task motivation: impact, competence, meaningfulness, and choice. Competence is similar to Bandura's concept of self-efficacy. We will refer generally to intrinsic task motivation as a factor in delegability, but it is worth keeping in mind the possible variables behind it. Meaningfulness is likely particularly salient when considering task delegation [cite? meaning came up a lot in the class survey]. Practically, Maslow's (1943) hierarchy need theory has modern acceptance in explaining need-based actions, and values are used to explain individual differences in actions in given situations \cite{latham2005work}.

Goal Setting Theory examines the factors behind an effective goal, especially the effects of conscious motivation on performance. Locke et. al. define a goal as "the object or aim of an action." Such effects are strongest when people are more committed to their goals, and goal commitment is suggested to arise from (1) believing the goal outcome is important and (2) higher self-efficacy, discussed later. A belief in goal importance may come from a public commitment, incentives, or motives \cite{locke-goal}. [Accountability may also be considered here]

Generally, a goal may be performance-oriented or mastery-oriented [cite?]. Performance goals emphasize achieving certain external metrics or recognition, while someone with a mastery goal is instead more interested in learning and acquiring skills and strategies. [clarify the distinction btw extrinsically-motivated goals and intrinsic vs this]

[add section on utility or goal importance] 

A decision on the delegation of a given task can vary between individuals. A large part of this variability may be explained by differences in the motivation, values, goals, and utility[cite?]. These factors combined can be summarized as: is the person motivated to actually undertake the task themselves, and does delegating it undermine or support the goal?

\subsection{Difficulty}
We suggest that perceived task difficulty is the second major dimension. Difficulty can be decomposed into three main variables: estimated effort required, estimated abilities required, and self-efficacy.

In a study of insurance claims adjusters, \cite{leana1986predictors} found that subordinates considered to be more "capable, responsible, and trustworthy" were given more authority. Decision importance was also a significant predictor, negatively correlated with authority given.

%Leana, 1986; Keller, 1997).

Self-efficacy comes from Social Cognitive Theory in psychology, which is concerned with the workings of human agency -- how people can bring about changes in their lives \cite{Bandura-agency}. Among the requirements for human agency are self-reactiveness (motivating and constructing courses of action) and self-reflectiveness (personal examination of abilities and pursuits). %Properties of human agency are identified as intentionality, forethought, self-reactiveness, and self-reflectiveness. Self-reactiveness involves motivating and constructing courses of action. The last involves personal examination of abilities and pursuits. 

\cite{Bandura-89} defines self-efficacy as a person's "beliefs about their capabilities to exercise control over events that affect their lives." It can be thought of as a task-specific self-confidence: a high degree of self-efficacy means that an individual is confident in their ability to accomplish a task through effort. Self-efficacy  is partly a reflection of their actual capabilities (performance accomplishments), but it also arises through social persuasion and vicarious experience, and it depends on emotional states \cite{Bandura-89}.

Experience and confidence have been linked with delegation in several studies. This is thought to be because delegation involves a loss of control and an increase of ambiguity \cite{milewski1}, and confidence and experience helps to mitigate those concerns. Situational confidence is similar to self-efficacy.

A perception of difficulty may be poorly calibrated if the person has little experience with the task. If the person does have experience, we propose that self-efficacy is largely correlated with a perception of the task's difficulty. Note that if outcomes are more random or not perceived to be related to effort, then self-efficacy may not be as strongly linked with motivation and action \cite{Bandura-agency}.

Self-efficacy is also thought to affect motivation.  Individuals with low self-efficacy tend to avoid more challenging tasks, while higher self-efficacy can lead to more motivation and higher goals \cite{Bandura-89}.

We propose that self-efficacy can be at least partially explained in terms of personal experience/familiarity with the task and the skills or abilities required. More experience with the task would logically give rise to a deeper understanding of the challenges, strategies, and skills required to complete the task. If the person feels that they have the necessary abilities, then their self-efficacy would rise. [cite]

\subsection{Risk}
Risk is the third major dimension. Risk can be considered as the [cite: definition?]. We propose it is composed of personal accountability for the task outcome, the probability of errors, and the cost (or magnitude) of those errors. 

Cost-benefit analysis? Minimize error, maximize utility

\subsection{Trust}
Trust has enjoyed an extensive interest within the computer science community. Here, we will consider trust as a combination of perceived agent ability, perceived agent reliability, and perceived \textbf{value alignment}.

Trust is "the attitude that an agent will help achieve an individual's goals in a situation characterized by uncertainty and vulnerability" \cite{lee}. Because of the potential of automation to benefit society when used properly, factors behind appropriate degrees of reliance have been studied \cite{lee}. Trust is generally accepted as the most salient factor. People may over-trust or under-trust automation, resulting in misuse or disuse of the automation, respectively. 

As automation grows in complexity and uncertainty, a user's complete understanding of the automation becomes more intractable. Affective trust helps relax the cognitive demands of evaluating choice and expectations, enabling people to still make appropriate judgments \cite{lee}. 

In a framework 

Although trust is gen

\subsection{Task Factors}
\begin{enumerate}
    \item Task Complexity
    \item Task Importance (?)
    \item Task Difficulty
    \item Task Variability
\end{enumerate}

%\section{References}
%The references section should be labeled ``References" and should appear at the very end of the paper (don't end the paper with references, and then put a figure by itself on the last page). A sample list of references is given later on in these instructions. Please use a consistent format for references. Poorly prepared or sloppy references reflect badly on the quality of your paper and your research. Please prepare complete and accurate citations.

\section{Survey Design}
For the given task, please evaluate 
\subsection{Purpose}
\subsection{Difficulty}
\subsection{Risk}
\subsection{Trust}


\section{Example}
Example task: "Decide whether or not to release a defendant on bail awaiting trial."

Possible considerations under the framework:
\begin{enumerate}
    \item \textbf{Purpose:} Values may be fairness, justice, and compassion. How do I balance them? Say my goal is to achieve justice while maximizing fairness and compassion. 
    \item \textbf{Difficulty:} I do not have much experience judging since I've never done it. Low self-efficacy, no experience, social skills and law knowledge required, effort to read the files, listen, and decide. 
    \item \textbf{Risk:} As a citizen I'm not accountable individually unless involved with the case. Cost of error is the defendant's freedom and possibly causing their family hardship and heartache, vs. the possible victim if the defendant were to commit (another) crime. The probability of error is high.
    \item \textbf{Trust:} How well do I trust the AI agent to match my values here? 
\end{enumerate}

\section{Survey Data Experiments}

\subsection{Factor Weights and Predictive Model}
Split the 200 tasks into training, validation, and test data (1/3, 1/3, 1/3)? Use the survey results from some of the task data as a training, build a model, and present the accuracy of the model on a held-out test set.

\subsection{Clustering?}
People will use different thought processes and considerations when arriving at a delegation decision. For example, one person may tend to value personal meaning and motivation more than another person, who may favor utility along a more logical cost-benefit analysis. Maybe we can cluster on the factors and labels to produce different types of decision processes. May have to use individual responses rather than averaged task responses for this to work. 

\bibliography{cite}
\bibliographystyle{aaai}

\end{document}
